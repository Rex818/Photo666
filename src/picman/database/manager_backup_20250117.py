"""
Database manager for PyPhotoManager.
Handles SQLite database operations and schema management.
"""

import sqlite3
import sqlite_utils
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, date
import json
# import structlog  # å·²ç§»é™¤ï¼Œä½¿ç”¨æ ‡å‡†logging
import logging
from contextlib import contextmanager
import threading
import time
from functools import lru_cache


def safe_json_dumps(obj):
    """Safely serialize object to JSON, handling non-serializable types."""
    def convert(obj):
        if isinstance(obj, bytes):
            try:
                return obj.decode('utf-8')
            except UnicodeDecodeError:
                return str(obj)
        elif isinstance(obj, (datetime, date)):
            return obj.isoformat()
        elif not isinstance(obj, (str, int, float, bool, list, dict, type(None))):
            return str(obj)
        return obj
    
    def recursive_convert(obj):
        if isinstance(obj, dict):
            return {k: recursive_convert(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [recursive_convert(item) for item in obj]
        else:
            return convert(obj)
    
    return json.dumps(recursive_convert(obj))


class UnifiedTagsAccessor:
    """ç»Ÿä¸€æ ‡ç­¾è®¿é—®å™¨ - æä¾›æ™ºèƒ½è¯»å†™ç»Ÿä¸€æ ‡ç­¾å­—æ®µ"""
    
    @staticmethod
    def read_unified_tags(photo_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ™ºèƒ½è¯»å–æ ‡ç­¾æ•°æ® - ä¼˜å…ˆåˆ†ç¦»å­—æ®µï¼ˆæœ€æ–°æ•°æ®ï¼‰ï¼Œé™çº§åˆ°ç»Ÿä¸€å­—æ®µ"""
        try:
            # é¦–å…ˆæ£€æŸ¥åˆ†ç¦»å­—æ®µæ˜¯å¦æœ‰æœ€æ–°æ•°æ®
            separate_fields_data = UnifiedTagsAccessor._build_from_separate_fields(photo_data)
            
            # æ£€æŸ¥åˆ†ç¦»å­—æ®µæ˜¯å¦æœ‰ä¸­æ–‡å†…å®¹ï¼ˆç¿»è¯‘ç»“æžœï¼‰
            has_chinese_content = any([
                separate_fields_data["simple"]["zh"],
                separate_fields_data["normal"]["zh"], 
                separate_fields_data["detailed"]["zh"]
            ])
            
            # å¦‚æžœæœ‰ä¸­æ–‡å†…å®¹ï¼Œè¯´æ˜Žæœ‰æœ€æ–°çš„ç¿»è¯‘ç»“æžœï¼Œä¼˜å…ˆä½¿ç”¨åˆ†ç¦»å­—æ®µ
            if has_chinese_content:
                print(f"ðŸ” ä½¿ç”¨åˆ†ç¦»å­—æ®µæ•°æ®ï¼ˆåŒ…å«æœ€æ–°ç¿»è¯‘ï¼‰: {has_chinese_content}")
                return separate_fields_data
            
            # å¦‚æžœæ²¡æœ‰ä¸­æ–‡å†…å®¹ï¼Œå°è¯•ä»Žç»Ÿä¸€å­—æ®µè¯»å–
            unified_tags_str = photo_data.get("unified_tags")
            if unified_tags_str and unified_tags_str.strip():
                try:
                    unified_tags = json.loads(unified_tags_str)
                    print(f"ðŸ” ä½¿ç”¨ç»Ÿä¸€å­—æ®µæ•°æ®: æ— ä¸­æ–‡å†…å®¹")
                    return unified_tags
                except json.JSONDecodeError:
                    pass
            
            # æœ€åŽä½¿ç”¨åˆ†ç¦»å­—æ®µ
            print(f"ðŸ” ä½¿ç”¨åˆ†ç¦»å­—æ®µæ•°æ®ï¼ˆé»˜è®¤ï¼‰")
            return separate_fields_data
            
        except Exception as e:
            print(f"ðŸ” è¯»å–ç»Ÿä¸€æ ‡ç­¾å¤±è´¥: {e}")
            return UnifiedTagsAccessor._get_empty_structure()
    
    @staticmethod
    def _build_from_separate_fields(photo_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä»Žåˆ†ç¦»å­—æ®µæž„å»ºç»Ÿä¸€ç»“æž„"""
        try:
            unified_tags = {
                "simple": {
                    "en": UnifiedTagsAccessor._normalize_field(photo_data.get("simple_tags_en", "")),
                    "zh": UnifiedTagsAccessor._normalize_field(photo_data.get("simple_tags_cn", ""))
                },
                "normal": {
                    "en": UnifiedTagsAccessor._normalize_field(photo_data.get("general_tags_en", "")),
                    "zh": UnifiedTagsAccessor._normalize_field(photo_data.get("general_tags_cn", ""))
                },
                "detailed": {
                    "en": UnifiedTagsAccessor._normalize_field(photo_data.get("detailed_tags_en", "")),
                    "zh": UnifiedTagsAccessor._normalize_field(photo_data.get("detailed_tags_cn", ""))
                },
                "notes": UnifiedTagsAccessor._normalize_field(photo_data.get("notes", "")),
                "metadata": {
                    "source": "separate_fields",
                    "last_updated": datetime.now().isoformat()
                }
            }
            return unified_tags
        except Exception:
            return UnifiedTagsAccessor._get_empty_structure()
    
    @staticmethod
    def _normalize_field(field_value: Any) -> str:
        """è§„èŒƒåŒ–å­—æ®µå€¼"""
        if not field_value:
            return ""
        
        if isinstance(field_value, str):
            # å¤„ç†JSONæ•°ç»„æ ¼å¼
            if field_value.startswith('[') and field_value.endswith(']'):
                try:
                    tag_list = json.loads(field_value)
                    if isinstance(tag_list, list):
                        return ', '.join(str(tag) for tag in tag_list if tag)
                except json.JSONDecodeError:
                    pass
            return field_value.strip()
        
        return str(field_value).strip()
    
    @staticmethod
    def _get_empty_structure() -> Dict[str, Any]:
        """èŽ·å–ç©ºçš„ç»Ÿä¸€æ ‡ç­¾ç»“æž„"""
        return {
            "simple": {"en": "", "zh": ""},
            "normal": {"en": "", "zh": ""},
            "detailed": {"en": "", "zh": ""},
            "notes": "",
            "metadata": {
                "source": "empty",
                "last_updated": datetime.now().isoformat()
            }
        }
    
    @staticmethod
    def write_unified_tags(unified_tags: Dict[str, Any]) -> Dict[str, Any]:
        """å°†ç»Ÿä¸€æ ‡ç­¾ç»“æž„è½¬æ¢ä¸ºæ•°æ®åº“æ›´æ–°å­—å…¸ - åŒå†™ç­–ç•¥"""
        try:
            print(f"ðŸ” å¼€å§‹å¤„ç†ç»Ÿä¸€æ ‡ç­¾å†™å…¥: {unified_tags}")
            
            # éªŒè¯å’Œè§„èŒƒåŒ–ç»Ÿä¸€æ ‡ç­¾ç»“æž„
            normalized_tags = UnifiedTagsAccessor._validate_and_normalize(unified_tags)
            print(f"ðŸ” è§„èŒƒåŒ–åŽçš„æ ‡ç­¾: {normalized_tags}")
            
            # æž„å»ºæ›´æ–°å­—å…¸ - åŒå†™ï¼šç»Ÿä¸€å­—æ®µ + åˆ†ç¦»å­—æ®µ
            updates = {
                # æ–°çš„ç»Ÿä¸€å­—æ®µ
                "unified_tags": json.dumps(normalized_tags, ensure_ascii=False),
                
                # å…¼å®¹çš„åˆ†ç¦»å­—æ®µ
                "simple_tags_en": normalized_tags["simple"]["en"],
                "simple_tags_cn": normalized_tags["simple"]["zh"],
                "general_tags_en": normalized_tags["normal"]["en"], 
                "general_tags_cn": normalized_tags["normal"]["zh"],
                "detailed_tags_en": normalized_tags["detailed"]["en"],
                "detailed_tags_cn": normalized_tags["detailed"]["zh"],
                "notes": normalized_tags["notes"]
            }
            
            print(f"ðŸ” ç”Ÿæˆçš„æ›´æ–°å­—å…¸: {updates}")
            return updates
            
        except Exception as e:
            print(f"âŒ ç»Ÿä¸€æ ‡ç­¾å†™å…¥å¤±è´¥: {str(e)}")
            raise
    
    @staticmethod
    def _validate_and_normalize(unified_tags: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å’Œè§„èŒƒåŒ–ç»Ÿä¸€æ ‡ç­¾ç»“æž„"""
        try:
            # ç¡®ä¿åŸºæœ¬ç»“æž„å­˜åœ¨
            normalized = {
                "simple": {"en": "", "zh": ""},
                "normal": {"en": "", "zh": ""},
                "detailed": {"en": "", "zh": ""},
                "notes": "",
                "metadata": {
                    "last_updated": datetime.now().isoformat(),
                    "source": "unified_write"
                }
            }
            
            # å®‰å…¨åœ°å¤åˆ¶ç”¨æˆ·æ•°æ®
            if isinstance(unified_tags, dict):
                for category in ["simple", "normal", "detailed"]:
                    if category in unified_tags and isinstance(unified_tags[category], dict):
                        for lang in ["en", "zh"]:
                            if lang in unified_tags[category]:
                                content = str(unified_tags[category][lang]).strip()
                                # éªŒè¯é•¿åº¦é™åˆ¶ (2048å­—èŠ‚)
                                if len(content.encode('utf-8')) > 2048:
                                    content_bytes = content.encode('utf-8')
                                    content = content_bytes[:2045].decode('utf-8', errors='ignore') + '...'
                                normalized[category][lang] = content
                
                # å¤„ç†å¤‡æ³¨å­—æ®µ
                if "notes" in unified_tags:
                    notes = str(unified_tags["notes"]).strip()
                    if len(notes.encode('utf-8')) > 2048:
                        notes_bytes = notes.encode('utf-8')
                        notes = notes_bytes[:2045].decode('utf-8', errors='ignore') + '...'
                    normalized["notes"] = notes
                
                # ä¿ç•™ç”¨æˆ·å…ƒæ•°æ®
                if "metadata" in unified_tags and isinstance(unified_tags["metadata"], dict):
                    normalized["metadata"].update(unified_tags["metadata"])
                    normalized["metadata"]["last_updated"] = datetime.now().isoformat()
            
            return normalized
            
        except Exception as e:
            raise


class DatabaseManager:
    """Manages SQLite database operations for photo management."""
    
    def __init__(self, db_path: str, config=None):
        self.db_path = Path(db_path)
        self.config = config
        self.logger = logging.getLogger("picman.database")
        
        # Ensure database directory exists
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Initialize database
        self._init_database()
    
    def execute(self, query: str, params: tuple = None) -> bool:
        """Execute SQL query with unified tags compatibility layer."""
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡ç­¾å­—æ®µæ›´æ–°æ“ä½œ
            if query.strip().upper().startswith("UPDATE PHOTOS SET") and params:
                self.logger.debug("Checking compatibility layer for UPDATE photos SET query")
                return self._handle_compatible_update(query, params)
            
            # æ™®é€šæŸ¥è¯¢æ‰§è¡Œ
            with self.get_connection() as conn:
                cursor = conn.cursor()
                if params:
                    cursor.execute(query, params)
                else:
                    cursor.execute(query)
                conn.commit()
                return True
                
        except Exception as e:
            self.logger.error(f"Failed to execute query: {str(e)}")
            return False
    
    def _handle_compatible_update(self, query: str, params: tuple) -> bool:
        """å¤„ç†å…¼å®¹æ€§æ ‡ç­¾å­—æ®µæ›´æ–° - ä¸ºFlorence2ç­‰æ’ä»¶æä¾›æ”¯æŒ"""
        try:
            # è§£æžUPDATEè¯­å¥ä»¥ç¡®å®šæ›´æ–°çš„å­—æ®µ
            import re
            
            # åŒ¹é… "UPDATE photos SET field_name = ? WHERE id = ?" æ ¼å¼
            match = re.match(r'UPDATE\s+photos\s+SET\s+(\w+)\s*=\s*\?\s+WHERE\s+id\s*=\s*\?', query, re.IGNORECASE)
            
            if match and len(params) == 2:
                field_name = match.group(1)
                field_value, photo_id = params
                
                # æ ‡ç­¾å­—æ®µæ˜ å°„
                tag_fields = {
                    "simple_tags_en", "simple_tags_cn",
                    "general_tags_en", "general_tags_cn", 
                    "detailed_tags_en", "detailed_tags_cn",
                    "notes"
                }
                
                if field_name in tag_fields:
                    self.logger.debug(f"Intercepted tag field update for compatibility: field={field_name}, photo_id={photo_id}")
                    return self._update_tag_field_with_sync(photo_id, field_name, field_value)
            
            # ä¸æ˜¯æ ‡ç­¾å­—æ®µæ›´æ–°ï¼Œç›´æŽ¥æ‰§è¡Œ
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(query, params)
                conn.commit()
                return True
                
        except Exception as e:
            self.logger.error(f"Failed to handle compatible update: {str(e)}")
            return False
    
    def _update_tag_field_with_sync(self, photo_id: int, field_name: str, field_value: str) -> bool:
        """æ›´æ–°æ ‡ç­¾å­—æ®µå¹¶åŒæ­¥åˆ°ç»Ÿä¸€å­—æ®µ"""
        try:
            # èŽ·å–å½“å‰ç…§ç‰‡æ•°æ®
            photo_data = self.get_photo(photo_id)
            if not photo_data:
                self.logger.error(f"Photo not found for sync update: photo_id={photo_id}")
                return False
            
            # èŽ·å–å½“å‰ç»Ÿä¸€æ ‡ç­¾
            unified_tags = UnifiedTagsAccessor.read_unified_tags(photo_data)
            
            # å­—æ®µæ˜ å°„
            field_mapping = {
                "simple_tags_en": ("simple", "en"),
                "simple_tags_cn": ("simple", "zh"),
                "general_tags_en": ("normal", "en"),
                "general_tags_cn": ("normal", "zh"),
                "detailed_tags_en": ("detailed", "en"),
                "detailed_tags_cn": ("detailed", "zh"),
                "notes": ("notes", None)
            }
            
            if field_name in field_mapping:
                category, lang = field_mapping[field_name]
                
                # æ›´æ–°ç»Ÿä¸€ç»“æž„
                if lang:
                    if category not in unified_tags:
                        unified_tags[category] = {"en": "", "zh": ""}
                    unified_tags[category][lang] = str(field_value).strip()
                else:
                    unified_tags[category] = str(field_value).strip()
                
                # ç›´æŽ¥ä½¿ç”¨ä½Žçº§APIæ›´æ–°ï¼Œé¿å…é€’å½’è°ƒç”¨
                updates = UnifiedTagsAccessor.write_unified_tags(unified_tags)
                
                # ç›´æŽ¥æ•°æ®åº“æ›´æ–°ï¼Œä¸é€šè¿‡update_photoé¿å…é€’å½’
                with self.get_connection() as conn:
                    cursor = conn.cursor()
                    
                    # æž„å»ºUPDATEè¯­å¥
                    set_clauses = []
                    values = []
                    for key, value in updates.items():
                        set_clauses.append(f"{key} = ?")
                        values.append(value)
                    
                    set_clauses.append("date_modified = ?")
                    values.append(datetime.now().isoformat())
                    values.append(photo_id)
                    
                    query = f"UPDATE photos SET {', '.join(set_clauses)} WHERE id = ?"
                    cursor.execute(query, values)
                    conn.commit()
                
                self.logger.debug(f"Successfully synced tag field update: photo_id={photo_id}, field={field_name}")
                return True
            else:
                # éžæ ‡ç­¾å­—æ®µï¼Œç›´æŽ¥æ›´æ–°
                with self.get_connection() as conn:
                    cursor = conn.cursor()
                    cursor.execute(f"UPDATE photos SET {field_name} = ? WHERE id = ?", (field_value, photo_id))
                    conn.commit()
                    return True
                
        except Exception as e:
            self.logger.error(f"Failed to update tag field with sync: photo_id={photo_id}, field={field_name}, error={str(e)}")
            return False
    
    def _init_database(self):
        """Initialize database with required tables."""
        try:
            db = sqlite_utils.Database(self.db_path)
            
            # Photos table
            if not db["photos"].exists():
                db["photos"].create({
                    "id": int,
                    "filename": str,
                    "filepath": str,
                    "file_size": int,
                    "file_hash": str,
                    "width": int,
                    "height": int,
                    "format": str,
                    "date_taken": str,
                    "date_added": str,
                    "date_modified": str,
                    "exif_data": str,  # JSON string
                    "ai_metadata": str,  # JSON string - AIå…ƒæ•°æ®
                    "is_ai_generated": bool,  # æ˜¯å¦ä¸ºAIç”Ÿæˆ
                    "tags": str,       # JSON array
                    "simple_tags": str,    # JSON array - ç®€å•æ ‡ç­¾
                    "normal_tags": str,    # JSON array - æ™®é€šæ ‡ç­¾
                    "detailed_tags": str,  # JSON array - è¯¦ç»†æ ‡ç­¾
                    "tag_translations": str,  # JSON object - æ ‡ç­¾ç¿»è¯‘
                    "rating": int,
                    "is_favorite": bool,
                    "thumbnail_path": str,
                    "notes": str
                }, pk="id")
                
                # Create indexes for performance optimization
                db["photos"].create_index(["filepath"], unique=True)
                db["photos"].create_index(["file_hash"])
                db["photos"].create_index(["date_taken"])
                db["photos"].create_index(["rating"])
                db["photos"].create_index(["is_favorite"])
                # Additional performance indexes
                db["photos"].create_index(["filename"])
                db["photos"].create_index(["file_size"])
                db["photos"].create_index(["date_taken", "rating"])  # Composite index for sorting
                db["photos"].create_index(["is_favorite", "rating"])  # For favorite photos sorting
            else:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ æ–°å­—æ®µ
                self._add_new_columns_if_needed(db)
            
            # Albums table
            if not db["albums"].exists():
                db["albums"].create({
                    "id": int,
                    "name": str,
                    "description": str,
                    "created_date": str,
                    "cover_photo_id": int,
                    "photo_count": int
                }, pk="id")
                
                db["albums"].create_index(["name"], unique=True)
            
            # Album photos junction table
            if not db["album_photos"].exists():
                db["album_photos"].create({
                    "album_id": int,
                    "photo_id": int,
                    "added_date": str
                }, pk=["album_id", "photo_id"])
                
                db["album_photos"].add_foreign_key("album_id", "albums", "id")
                db["album_photos"].add_foreign_key("photo_id", "photos", "id")
            
            # Tags table
            if not db["tags"].exists():
                db["tags"].create({
                    "id": int,
                    "name": str,
                    "color": str,
                    "usage_count": int
                }, pk="id")
                
                db["tags"].create_index(["name"], unique=True)
            
            # Settings table
            if not db["settings"].exists():
                db["settings"].create({
                    "key": str,
                    "value": str,
                    "updated_date": str
                }, pk="key")
            
            self.logger.info(f"Database initialized successfully: {str(self.db_path)}")
            
        except Exception as e:
            self.logger.error(f"Failed to initialize database: {str(e)}")
            raise
    
    def _add_new_columns_if_needed(self, db):
        """Add new columns to existing photos table if they don't exist."""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # æ£€æŸ¥æ–°å­—æ®µæ˜¯å¦å­˜åœ¨
                cursor.execute("PRAGMA table_info(photos)")
                columns = [column[1] for column in cursor.fetchall()]
                
                # éœ€è¦æ·»åŠ çš„æ–°å­—æ®µ
                new_columns = [
                    ("simple_tags", "TEXT DEFAULT '[]'"),
                    ("normal_tags", "TEXT DEFAULT '[]'"),
                    ("detailed_tags", "TEXT DEFAULT '[]'"),
                    ("tag_translations", "TEXT DEFAULT '{}'"),
                    ("ai_metadata", "TEXT DEFAULT '{}'"),
                    ("is_ai_generated", "BOOLEAN DEFAULT 0"),
                    # æ–°çš„åˆ†ç¦»å¼æ ‡ç­¾å­—æ®µ
                    ("simple_tags_en", "TEXT DEFAULT ''"),
                    ("simple_tags_cn", "TEXT DEFAULT ''"),
                    ("general_tags_en", "TEXT DEFAULT ''"),
                    ("general_tags_cn", "TEXT DEFAULT ''"),
                    ("detailed_tags_en", "TEXT DEFAULT ''"),
                    ("detailed_tags_cn", "TEXT DEFAULT ''"),
                    ("positive_prompt", "TEXT DEFAULT ''"),
                    ("negative_prompt", "TEXT DEFAULT ''")
                ]
                
                for column_name, column_def in new_columns:
                    if column_name not in columns:
                        cursor.execute(f"ALTER TABLE photos ADD COLUMN {column_name} {column_def}")
                        self.logger.info(f"Added new column to photos table: {column_name}")
                
                conn.commit()
                
        except Exception as e:
            self.logger.error(f"Failed to add new columns: {str(e)}")
            raise
    
    @contextmanager
    def get_connection(self):
        """Get database connection with context manager."""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        try:
            yield conn
        finally:
            conn.close()
    
    def add_photo(self, photo_data: Dict[str, Any]) -> int:
        """Add a new photo to the database."""
        try:
            db = sqlite_utils.Database(self.db_path)
            
            # Prepare photo data
            photo_record = {
                "filename": photo_data["filename"],
                "filepath": photo_data["filepath"],
                "file_size": photo_data.get("file_size", 0),
                "file_hash": photo_data.get("file_hash", ""),
                "width": photo_data.get("width", 0),
                "height": photo_data.get("height", 0),
                "format": photo_data.get("format", ""),
                "date_taken": photo_data.get("date_taken", ""),
                "date_added": datetime.now().isoformat(),
                "date_modified": datetime.now().isoformat(),
                "exif_data": safe_json_dumps(photo_data.get("exif_data", {})),
                "tags": safe_json_dumps(photo_data.get("tags", [])),
                "simple_tags": safe_json_dumps(photo_data.get("simple_tags", [])),
                "normal_tags": safe_json_dumps(photo_data.get("normal_tags", [])),
                "detailed_tags": safe_json_dumps(photo_data.get("detailed_tags", [])),
                "tag_translations": safe_json_dumps(photo_data.get("tag_translations", {})),
                "ai_metadata": safe_json_dumps(photo_data.get("ai_metadata", {})),
                "is_ai_generated": photo_data.get("is_ai_generated", False),
                "rating": photo_data.get("rating", 0),
                "is_favorite": photo_data.get("is_favorite", False),
                "thumbnail_path": photo_data.get("thumbnail_path", ""),
                "notes": photo_data.get("notes", "")
            }
            
            result = db["photos"].insert(photo_record)
            photo_id = result.last_pk
            
            self.logger.info(f"Photo added to database: ID {photo_id}, filename {photo_data['filename']}")
            
            return photo_id
            
        except Exception as e:
            self.logger.error(f"Failed to add photo {photo_data.get('filename', 'unknown')}: {str(e)}")
            raise
    
    def get_photo(self, photo_id: int) -> Optional[Dict[str, Any]]:
        """Get photo by ID."""
        try:
            db = sqlite_utils.Database(self.db_path)
            photo = db["photos"].get(photo_id)
            
            if photo:
                # Parse JSON fields
                photo_dict = dict(photo)
                photo_dict["exif_data"] = json.loads(photo_dict["exif_data"])
                photo_dict["tags"] = json.loads(photo_dict["tags"])
                
                # ä½¿ç”¨ç»Ÿä¸€æ ‡ç­¾ç³»ç»Ÿè¯»å–æ ‡ç­¾æ•°æ®
                try:
                    unified_tags = UnifiedTagsAccessor.read_unified_tags(photo_dict)
                    
                    # ä¸ºå‘åŽå…¼å®¹ï¼Œä¿æŒåŽŸæœ‰å­—æ®µæ ¼å¼
                    photo_dict["unified_tags_data"] = unified_tags
                    
                    # åŒæ—¶ä¿æŒåˆ†ç¦»å­—æ®µçš„è®¿é—®æ–¹å¼ï¼ˆä»Žç»Ÿä¸€æ•°æ®ä¸­æå–ï¼‰
                    photo_dict["simple_tags_en"] = unified_tags.get("simple", {}).get("en", "")
                    photo_dict["simple_tags_cn"] = unified_tags.get("simple", {}).get("zh", "")
                    photo_dict["general_tags_en"] = unified_tags.get("normal", {}).get("en", "")
                    photo_dict["general_tags_cn"] = unified_tags.get("normal", {}).get("zh", "")
                    photo_dict["detailed_tags_en"] = unified_tags.get("detailed", {}).get("en", "")
                    photo_dict["detailed_tags_cn"] = unified_tags.get("detailed", {}).get("zh", "")
                    
                except Exception as e:
                    self.logger.error(f"Failed to read unified tags for photo {photo_dict.get('id')}: {str(e)}")
                    # é™çº§åˆ°ä¼ ç»Ÿè§£æžæ–¹å¼
                    unified_tags = UnifiedTagsAccessor._get_empty_structure()
                    photo_dict["unified_tags_data"] = unified_tags
                
                # è§£æžä¼ ç»Ÿæ ‡ç­¾å­—æ®µ - ä¿æŒå‘åŽå…¼å®¹
                try:
                    simple_tags_raw = photo_dict.get("simple_tags", "[]")
                    photo_dict["simple_tags"] = json.loads(simple_tags_raw) if simple_tags_raw.strip() else []
                except (json.JSONDecodeError, AttributeError):
                    photo_dict["simple_tags"] = []
                
                try:
                    normal_tags_raw = photo_dict.get("normal_tags", "[]")
                    photo_dict["normal_tags"] = json.loads(normal_tags_raw) if normal_tags_raw.strip() else []
                except (json.JSONDecodeError, AttributeError):
                    photo_dict["normal_tags"] = []
                
                try:
                    detailed_tags_raw = photo_dict.get("detailed_tags", "[]")
                    photo_dict["detailed_tags"] = json.loads(detailed_tags_raw) if detailed_tags_raw.strip() else []
                except (json.JSONDecodeError, AttributeError):
                    photo_dict["detailed_tags"] = []
                
                try:
                    tag_translations_raw = photo_dict.get("tag_translations", "{}")
                    photo_dict["tag_translations"] = json.loads(tag_translations_raw) if tag_translations_raw.strip() else {}
                except (json.JSONDecodeError, AttributeError):
                    photo_dict["tag_translations"] = {}
                
                # è§£æžAIå…ƒæ•°æ®å­—æ®µ
                ai_metadata_str = photo_dict.get("ai_metadata")
                if ai_metadata_str and ai_metadata_str.strip():
                    try:
                        photo_dict["ai_metadata"] = json.loads(ai_metadata_str)
                    except (json.JSONDecodeError, TypeError):
                        self.logger.warning("Failed to parse AI metadata JSON: photo_id=%s", photo_id, 
                                          ai_metadata_str=ai_metadata_str)
                        photo_dict["ai_metadata"] = {}
                else:
                    photo_dict["ai_metadata"] = {}
                photo_dict["is_ai_generated"] = bool(photo_dict.get("is_ai_generated", False))
                
                return photo_dict
            
            return None
            
        except Exception as e:
            self.logger.error(f"Failed to get photo {photo_id}: {str(e)}")
            return None
    
    def search_photos(self, 
                     query: str = "",
                     search_terms: List[str] = None,
                     tags: List[str] = None,
                     rating_min: int = 0,
                     favorites_only: bool = False,
                     min_width: int = 0,
                     min_height: int = 0,
                     min_size_kb: int = 0,
                     camera_filter: str = "",
                     date_from: str = "",
                     date_to: str = "",
                     limit: int = 100,
                     offset: int = 0) -> List[Dict[str, Any]]:
        """Enhanced search photos with various filters."""
        try:
            db = sqlite_utils.Database(self.db_path)
            
            # è®°å½•æœç´¢å‚æ•°ç”¨äºŽè°ƒè¯•
            self.logger.info(f"Search parameters: query='{query}', search_terms={search_terms}, tags={tags}, rating_min={rating_min}, favorites_only={favorites_only}, min_width={min_width}, min_height={min_height}, min_size_kb={min_size_kb}, camera_filter='{camera_filter}', date_from='{date_from}', date_to='{date_to}'")
            
            sql_conditions = []
            params = []
            
            # åŸºç¡€æ–‡æœ¬æœç´¢ï¼ˆæ–‡ä»¶åã€å¤‡æ³¨ï¼‰
            if query:
                sql_conditions.append("(filename LIKE ? OR notes LIKE ?)")
                params.extend([f"%{query}%", f"%{query}%"])
            
            # æ™ºèƒ½å…³é”®è¯æœç´¢ï¼ˆæ”¯æŒçŸ­å¥å’Œå•è¯ï¼Œä¼˜åŒ–ä¸­æ–‡æœç´¢ï¼‰
            if search_terms:
                term_conditions = []
                for term in search_terms:
                    # åœ¨æ–‡ä»¶åã€å¤‡æ³¨ã€æ ‡ç­¾ã€AIå…ƒæ•°æ®ä¸­æœç´¢ï¼ŒåŒ…æ‹¬ä¸­è‹±æ–‡æ ‡ç­¾
                    term_conditions.append("""
                        (filename LIKE ? OR notes LIKE ? OR 
                         simple_tags LIKE ? OR normal_tags LIKE ? OR detailed_tags LIKE ? OR
                         tag_translations LIKE ? OR
                         json_extract(tag_translations, '$.' || ?) LIKE ? OR
                         ai_metadata LIKE ? OR
                         json_extract(ai_metadata, '$.positive_prompt') LIKE ? OR
                         json_extract(ai_metadata, '$.model_name') LIKE ?)
                    """)
                    params.extend([f"%{term}%"] * 6 + [term, f"%{term}%", f"%{term}%", f"%{term}%", f"%{term}%"])
                
                if term_conditions:
                    sql_conditions.append(f"({' OR '.join(term_conditions)})")
            
            # æ ‡ç­¾ç­›é€‰
            if tags:
                tag_conditions = []
                for tag in tags:
                    tag_conditions.append("""
                        (simple_tags LIKE ? OR normal_tags LIKE ? OR detailed_tags LIKE ? OR
                         tag_translations LIKE ?)
                    """)
                    params.extend([f"%{tag}%"] * 4)
                
                if tag_conditions:
                    sql_conditions.append(f"({' OR '.join(tag_conditions)})")
            
            # è¯„åˆ†ç­›é€‰
            if rating_min > 0:
                sql_conditions.append("rating >= ?")
                params.append(rating_min)
            
            # æ”¶è—ç­›é€‰
            if favorites_only:
                sql_conditions.append("is_favorite = 1")
            
            # å°ºå¯¸ç­›é€‰
            if min_width > 0:
                sql_conditions.append("width >= ?")
                params.append(min_width)
            
            if min_height > 0:
                sql_conditions.append("height >= ?")
                params.append(min_height)
            
            # æ–‡ä»¶å¤§å°ç­›é€‰ï¼ˆè½¬æ¢ä¸ºå­—èŠ‚ï¼‰
            if min_size_kb > 0:
                min_size_bytes = min_size_kb * 1024
                sql_conditions.append("file_size >= ?")
                params.append(min_size_bytes)
            
            # ç›¸æœºä¿¡æ¯ç­›é€‰
            if camera_filter:
                sql_conditions.append("exif_data LIKE ?")
                params.append(f"%{camera_filter}%")
            
            # æ—¥æœŸèŒƒå›´ç­›é€‰
            if date_from:
                sql_conditions.append("date_taken >= ?")
                params.append(date_from)
            
            if date_to:
                sql_conditions.append("date_taken <= ?")
                params.append(date_to)
            
            # æž„å»ºSQLæŸ¥è¯¢ - ä½¿ç”¨æ›´çµæ´»çš„ORé€»è¾‘
            sql = "SELECT * FROM photos"
            if sql_conditions:
                # å°†æœç´¢æ¡ä»¶åˆ†ç»„ï¼šæ–‡æœ¬æœç´¢ä½¿ç”¨ORï¼Œå…¶ä»–ç­›é€‰ä½¿ç”¨AND
                text_conditions = []
                filter_conditions = []
                
                for condition in sql_conditions:
                    if "LIKE" in condition and ("filename" in condition or "notes" in condition or "simple_tags" in condition or "normal_tags" in condition or "detailed_tags" in condition or "tag_translations" in condition):
                        text_conditions.append(condition)
                    else:
                        filter_conditions.append(condition)
                
                where_clauses = []
                
                # æ–‡æœ¬æœç´¢æ¡ä»¶ä½¿ç”¨ORè¿žæŽ¥
                if text_conditions:
                    where_clauses.append(f"({' OR '.join(text_conditions)})")
                
                # å…¶ä»–ç­›é€‰æ¡ä»¶ä½¿ç”¨ANDè¿žæŽ¥
                if filter_conditions:
                    where_clauses.append(f"({' AND '.join(filter_conditions)})")
                
                if where_clauses:
                    sql += " WHERE " + " AND ".join(where_clauses)
            
            sql += " ORDER BY date_taken DESC, date_added DESC"
            sql += f" LIMIT {limit} OFFSET {offset}"
            
            # è®°å½•SQLæŸ¥è¯¢ç”¨äºŽè°ƒè¯•
            self.logger.info(f"SQL query: {sql}, params: {params}")
            
            with self.get_connection() as conn:
                cursor = conn.execute(sql, params)
                photos = []
                
                for row in cursor.fetchall():
                    photo_dict = dict(row)
                    
                    # å®‰å…¨è§£æžJSONå­—æ®µ
                    try:
                        photo_dict["exif_data"] = json.loads(photo_dict.get("exif_data", "{}"))
                    except:
                        photo_dict["exif_data"] = {}
                    
                    try:
                        photo_dict["tags"] = json.loads(photo_dict.get("tags", "[]"))
                    except:
                        photo_dict["tags"] = []
                    
                    # è§£æžæ–°çš„æ ‡ç­¾å­—æ®µ
                    try:
                        photo_dict["simple_tags"] = json.loads(photo_dict.get("simple_tags", "[]"))
                    except:
                        photo_dict["simple_tags"] = []
                    
                    try:
                        photo_dict["normal_tags"] = json.loads(photo_dict.get("normal_tags", "[]"))
                    except:
                        photo_dict["normal_tags"] = []
                    
                    try:
                        photo_dict["detailed_tags"] = json.loads(photo_dict.get("detailed_tags", "[]"))
                    except:
                        photo_dict["detailed_tags"] = []
                    
                    try:
                        photo_dict["tag_translations"] = json.loads(photo_dict.get("tag_translations", "{}"))
                    except:
                        photo_dict["tag_translations"] = {}
                    
                    # è§£æžAIå…ƒæ•°æ®å­—æ®µ
                    try:
                        photo_dict["ai_metadata"] = json.loads(photo_dict.get("ai_metadata", "{}"))
                    except:
                        photo_dict["ai_metadata"] = {}
                    
                    try:
                        photo_dict["is_ai_generated"] = bool(photo_dict.get("is_ai_generated", False))
                    except:
                        photo_dict["is_ai_generated"] = False
                    
                    photos.append(photo_dict)
                
                self.logger.info(f"Search results: {len(photos)}")
                return photos
                
        except Exception as e:
            self.logger.error(f"Failed to search photos: {str(e)}")
            return []
    
    def update_photo(self, photo_id: int, updates: Dict[str, Any]) -> bool:
        """Update photo record with unified tags support."""
        try:
            db = sqlite_utils.Database(self.db_path)
            
            # Prepare updates
            update_data = updates.copy()
            update_data["date_modified"] = datetime.now().isoformat()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç»Ÿä¸€æ ‡ç­¾æ›´æ–°
            if "unified_tags_data" in update_data:
                try:
                    # å¤„ç†ç»Ÿä¸€æ ‡ç­¾æ›´æ–° - åŒå†™ç­–ç•¥
                    print(f"ðŸ” æ£€æµ‹åˆ°ç»Ÿä¸€æ ‡ç­¾æ›´æ–°: photo_id={photo_id}")
                    unified_tags = update_data.pop("unified_tags_data")
                    print(f"ðŸ” ç»Ÿä¸€æ ‡ç­¾æ•°æ®: {unified_tags}")
                    dual_write_updates = UnifiedTagsAccessor.write_unified_tags(unified_tags)
                    print(f"ðŸ” åŒå†™æ›´æ–°å­—å…¸: {dual_write_updates}")
                    update_data.update(dual_write_updates)
                    print(f"ðŸ” åˆå¹¶åŽçš„æ›´æ–°æ•°æ®: {update_data}")
                    self.logger.info(f"Applied unified tags dual-write for photo {photo_id}")
                except Exception as e:
                    print(f"âŒ ç»Ÿä¸€æ ‡ç­¾å¤„ç†å¤±è´¥: {str(e)}")
                    self.logger.error(f"Failed to process unified tags update for photo {photo_id}: {str(e)}")
            
            # Handle JSON fields
            if "exif_data" in update_data and isinstance(update_data["exif_data"], dict):
                update_data["exif_data"] = safe_json_dumps(update_data["exif_data"])
            
            if "tags" in update_data and isinstance(update_data["tags"], list):
                update_data["tags"] = safe_json_dumps(update_data["tags"])
            
            # å¤„ç†æ–°çš„æ ‡ç­¾å­—æ®µ
            if "simple_tags" in update_data and isinstance(update_data["simple_tags"], list):
                update_data["simple_tags"] = safe_json_dumps(update_data["simple_tags"])
            
            if "normal_tags" in update_data and isinstance(update_data["normal_tags"], list):
                update_data["normal_tags"] = safe_json_dumps(update_data["normal_tags"])
            
            if "detailed_tags" in update_data and isinstance(update_data["detailed_tags"], list):
                update_data["detailed_tags"] = safe_json_dumps(update_data["detailed_tags"])
            
            if "tag_translations" in update_data and isinstance(update_data["tag_translations"], dict):
                update_data["tag_translations"] = safe_json_dumps(update_data["tag_translations"])
            
            # å¤„ç†æ–°çš„åˆ†ç¦»å¼æ ‡ç­¾å­—æ®µï¼ˆè‹±æ–‡/ä¸­æ–‡ï¼‰
            if "simple_tags_en" in update_data:
                update_data["simple_tags_en"] = str(update_data["simple_tags_en"])
            if "simple_tags_cn" in update_data:
                update_data["simple_tags_cn"] = str(update_data["simple_tags_cn"])
            if "general_tags_en" in update_data:
                update_data["general_tags_en"] = str(update_data["general_tags_en"])
            if "general_tags_cn" in update_data:
                update_data["general_tags_cn"] = str(update_data["general_tags_cn"])
            if "detailed_tags_en" in update_data:
                update_data["detailed_tags_en"] = str(update_data["detailed_tags_en"])
            if "detailed_tags_cn" in update_data:
                update_data["detailed_tags_cn"] = str(update_data["detailed_tags_cn"])
            
            # å¤„ç†å…¶ä»–æ–°å­—æ®µ
            if "notes" in update_data:
                update_data["notes"] = str(update_data["notes"])
            if "positive_prompt" in update_data:
                update_data["positive_prompt"] = str(update_data["positive_prompt"])
            if "negative_prompt" in update_data:
                update_data["negative_prompt"] = str(update_data["negative_prompt"])
            
            # å¤„ç†AIå…ƒæ•°æ®å­—æ®µ
            if "ai_metadata" in update_data and isinstance(update_data["ai_metadata"], dict):
                update_data["ai_metadata"] = safe_json_dumps(update_data["ai_metadata"])
            
            db["photos"].update(photo_id, update_data)
            
            self.logger.info(f"Photo updated: ID {photo_id}")
            return True
            
        except Exception as e:
            self.logger.error("Failed to update photo: photo_id=%s, error=%s", photo_id, str(e))
            return False
    
    def delete_photo(self, photo_id: int) -> bool:
        """Delete photo from database."""
        try:
            db = sqlite_utils.Database(self.db_path)
            
            # Remove from albums first
            db["album_photos"].delete_where("photo_id = ?", [photo_id])
            
            # Delete photo record
            db["photos"].delete(photo_id)
            
            self.logger.info(f"Photo deleted: ID {photo_id}")
            return True
            
        except Exception as e:
            self.logger.error("Failed to delete photo: photo_id=%s, error=%s", photo_id, str(e))
            return False
    
    def get_stats(self) -> Dict[str, Any]:
        """Get database statistics."""
        try:
            db = sqlite_utils.Database(self.db_path)
            
            stats = {
                "total_photos": db["photos"].count,
                "total_albums": db["albums"].count,
                "total_tags": db["tags"].count,
                "favorites_count": db["photos"].count_where("is_favorite = 1"),
                "db_size": self.db_path.stat().st_size if self.db_path.exists() else 0
            }
            
            return stats
            
        except Exception as e:
            self.logger.error(f"Failed to get stats: {str(e)}")
            return {}
    
    def backup_database(self, backup_path: str) -> bool:
        """Create database backup."""
        try:
            backup_file = Path(backup_path)
            backup_file.parent.mkdir(parents=True, exist_ok=True)
            
            with self.get_connection() as source:
                backup_conn = sqlite3.connect(backup_file)
                source.backup(backup_conn)
                backup_conn.close()
            
            self.logger.info(f"Database backup created: {backup_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to create backup: {str(e)}")
            return False 

    def add_photo_to_album(self, photo_id: int, album_id: int) -> bool:
        """Add a photo to an album."""
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                db = sqlite_utils.Database(self.db_path)
                db["album_photos"].insert({
                    "album_id": album_id,
                    "photo_id": photo_id,
                    "added_date": datetime.now().isoformat()
                })
                return True
            except Exception as e:
                retry_count += 1
                self.logger.error(f"Failed to add photo to album (attempt {retry_count})", 
                                photo_id=photo_id, 
                                album_id=album_id, 
                                error=str(e))
                
                # If database is locked, wait and retry
                if "database is locked" in str(e).lower() and retry_count < max_retries:
                    import time
                    time.sleep(0.5 * retry_count)  # Exponential backoff
                    continue
                else:
                    break
        
        return False
    
    def get_album_photos(self, album_id: int) -> List[Dict[str, Any]]:
        """Get all photos in an album."""
        try:
            db = sqlite_utils.Database(self.db_path)
            
            photos = db.query("""
                SELECT p.* FROM photos p
                INNER JOIN album_photos ap ON p.id = ap.photo_id
                WHERE ap.album_id = ?
                ORDER BY ap.added_date DESC
            """, [album_id])
            
            result = []
            for photo in photos:
                photo_dict = dict(photo)
                photo_dict["exif_data"] = json.loads(photo_dict["exif_data"])
                photo_dict["tags"] = json.loads(photo_dict["tags"])
                
                # è§£æžæ–°çš„æ ‡ç­¾å­—æ®µ - å®‰å…¨å¤„ç†ç©ºå­—ç¬¦ä¸²
                try:
                    simple_tags_raw = photo_dict.get("simple_tags", "[]")
                    photo_dict["simple_tags"] = json.loads(simple_tags_raw) if simple_tags_raw.strip() else []
                except (json.JSONDecodeError, AttributeError):
                    photo_dict["simple_tags"] = []
                
                try:
                    normal_tags_raw = photo_dict.get("normal_tags", "[]")
                    photo_dict["normal_tags"] = json.loads(normal_tags_raw) if normal_tags_raw.strip() else []
                except (json.JSONDecodeError, AttributeError):
                    photo_dict["normal_tags"] = []
                
                try:
                    detailed_tags_raw = photo_dict.get("detailed_tags", "[]")
                    photo_dict["detailed_tags"] = json.loads(detailed_tags_raw) if detailed_tags_raw.strip() else []
                except (json.JSONDecodeError, AttributeError):
                    photo_dict["detailed_tags"] = []
                
                try:
                    tag_translations_raw = photo_dict.get("tag_translations", "{}")
                    photo_dict["tag_translations"] = json.loads(tag_translations_raw) if tag_translations_raw.strip() else {}
                except (json.JSONDecodeError, AttributeError):
                    photo_dict["tag_translations"] = {}
                
                # è§£æžAIå…ƒæ•°æ®å­—æ®µ - å®‰å…¨å¤„ç†
                try:
                    ai_metadata_raw = photo_dict.get("ai_metadata", "{}")
                    photo_dict["ai_metadata"] = json.loads(ai_metadata_raw) if ai_metadata_raw.strip() else {}
                except (json.JSONDecodeError, AttributeError):
                    photo_dict["ai_metadata"] = {}
                
                photo_dict["is_ai_generated"] = bool(photo_dict.get("is_ai_generated", False))
                
                result.append(photo_dict)
            
            return result
            
        except Exception as e:
            self.logger.error(f"Failed to get album photos: {str(e)}")
            return []
    
    def create_album(self, album_data: Dict[str, Any]) -> int:
        """Create a new album with automatic name conflict resolution."""
        try:
            db = sqlite_utils.Database(self.db_path)
            
            # æ£€æŸ¥åç§°æ˜¯å¦é‡å¤ï¼Œå¦‚æžœé‡å¤åˆ™è‡ªåŠ¨é‡å‘½å
            base_name = album_data["name"]
            final_name = base_name
            counter = 1
            
            # æ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT id FROM albums WHERE name = ?", (final_name,))
                existing_album = cursor.fetchone()
                
            while existing_album:
                final_name = f"{base_name} ({counter})"
                counter += 1
                
                # é˜²æ­¢æ— é™å¾ªçŽ¯
                if counter > 1000:
                    final_name = f"{base_name}_{int(time.time())}"
                    break
                
                with self.get_connection() as conn:
                    cursor = conn.cursor()
                    cursor.execute("SELECT id FROM albums WHERE name = ?", (final_name,))
                    existing_album = cursor.fetchone()
            
            # å¦‚æžœåç§°è¢«ä¿®æ”¹ï¼Œè®°å½•æ—¥å¿—
            if final_name != base_name:
                self.logger.info(f"Album name conflict resolved: '{base_name}' -> '{final_name}'")
            
            album_record = {
                "name": final_name,
                "description": album_data.get("description", ""),
                "created_date": datetime.now().isoformat(),
                "cover_photo_id": album_data.get("cover_photo_id", 0),
                "photo_count": 0
            }
            
            result = db["albums"].insert(album_record)
            album_id = result.last_pk
            
            self.logger.info(f"Album created: ID {album_id}, name '{final_name}'")
            return album_id
            
        except Exception as e:
            self.logger.error(f"Failed to create album: {str(e)}")
            raise
    
    def get_album(self, album_id: int) -> Optional[Dict[str, Any]]:
        """Get album by ID."""
        try:
            db = sqlite_utils.Database(self.db_path)
            album = db["albums"].get(album_id)
            
            if album:
                return dict(album)
            return None
            
        except Exception as e:
            self.logger.error(f"Failed to get album {album_id}: {str(e)}")
            return None
    
    def get_all_albums(self) -> List[Dict[str, Any]]:
        """Get all albums with photo count."""
        try:
            db = sqlite_utils.Database(self.db_path)
            
            albums = db.query("""
                SELECT a.*, COUNT(ap.photo_id) as photo_count
                FROM albums a
                LEFT JOIN album_photos ap ON a.id = ap.album_id
                GROUP BY a.id
                ORDER BY a.created_date DESC
            """)
            
            return [dict(album) for album in albums]
            
        except Exception as e:
            self.logger.error(f"Failed to get albums: {str(e)}")
            return []
    
    def update_album(self, album_id: int, updates: Dict[str, Any]) -> bool:
        """Update album information."""
        try:
            db = sqlite_utils.Database(self.db_path)
            db["albums"].update(album_id, updates)
            
            self.logger.info(f"Album updated: ID {album_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to update album {album_id}: {str(e)}")
            return False
    
    def get_photo_albums(self, photo_id: int) -> List[Dict[str, Any]]:
        """Get all albums that contain a specific photo."""
        try:
            db = sqlite_utils.Database(self.db_path)
            
            albums = db.query("""
                SELECT a.* FROM albums a
                JOIN album_photos ap ON a.id = ap.album_id
                WHERE ap.photo_id = ?
            """, [photo_id])
            
            return [dict(album) for album in albums]
            
        except Exception as e:
            self.logger.error(f"Failed to get photo albums {photo_id}: {str(e)}")
            return []
    
    def delete_album(self, album_id: int) -> bool:
        """Delete an album and only delete photos that are exclusive to this album."""
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                # Use context manager for better connection handling
                with self.get_connection() as conn:
                    # Get all photo IDs in this album first
                    photo_ids = [row[0] for row in conn.execute(
                        "SELECT photo_id FROM album_photos WHERE album_id = ?", [album_id]
                    ).fetchall()]
                    
                    # Delete tags for ALL photos in this album (regardless of other album memberships)
                    tags_deleted = 0
                    photos_deleted = 0
                    
                    for photo_id in photo_ids:
                        # Always delete photo tags for photos in this album
                        cursor = conn.execute("DELETE FROM photo_tags WHERE photo_id = ?", [photo_id])
                        tags_deleted += cursor.rowcount
                        
                        # Count how many albums this photo is in
                        album_count = conn.execute(
                            "SELECT COUNT(*) FROM album_photos WHERE photo_id = ?", [photo_id]
                        ).fetchone()[0]
                        
                        # If photo is only in this album, delete the photo record completely
                        if album_count == 1:
                            conn.execute("DELETE FROM photos WHERE id = ?", [photo_id])
                            photos_deleted += 1
                    
                    # Delete album-photo associations for this album
                    conn.execute("DELETE FROM album_photos WHERE album_id = ?", [album_id])
                    
                    # Delete the album record
                    conn.execute("DELETE FROM albums WHERE id = ?", [album_id])
                    
                    conn.commit()
                
                self.logger.info("Album deleted with complete cleanup: album_id=%s, photos_in_album=%d, tags_deleted=%d, photos_deleted=%d", 
                               album_id, len(photo_ids), tags_deleted, photos_deleted)
                return True
                
            except Exception as e:
                retry_count += 1
                self.logger.error("Failed to delete album (attempt %d): album_id=%s, error=%s", 
                                retry_count, album_id, str(e))
                
                # If database is locked, wait and retry
                if "database is locked" in str(e).lower() and retry_count < max_retries:
                    import time
                    time.sleep(0.5 * retry_count)  # Longer wait time
                    continue
                else:
                    break
        
        return False
    
    def delete_multiple_albums(self, album_ids: List[int]) -> Dict[str, Any]:
        """Delete multiple albums and only delete photos that are exclusive to these albums.
        
        Args:
            album_ids: List of album IDs to delete
            
        Returns:
            Dictionary with deletion results
        """
        if not album_ids:
            return {"success": False, "error": "No album IDs provided"}
        
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                with self.get_connection() as conn:
                    # Get album names for logging
                    album_names = {}
                    placeholders = ','.join(['?'] * len(album_ids))
                    cursor = conn.execute(f"SELECT id, name FROM albums WHERE id IN ({placeholders})", album_ids)
                    for row in cursor.fetchall():
                        album_names[row['id']] = row['name']
                    
                    # Get all photo IDs in these albums
                    cursor = conn.execute(f"SELECT photo_id FROM album_photos WHERE album_id IN ({placeholders})", album_ids)
                    all_photo_ids = [row[0] for row in cursor.fetchall()]
                    
                    # Count photos that will be deleted (exclusive to these albums)
                    photos_to_delete = []
                    for photo_id in set(all_photo_ids):  # Remove duplicates
                        # Count how many albums this photo is in
                        album_count = conn.execute(
                            "SELECT COUNT(*) FROM album_photos WHERE photo_id = ?", [photo_id]
                        ).fetchone()[0]
                        
                        # Count how many of those albums are in our deletion list
                        cursor = conn.execute(
                            f"SELECT COUNT(*) FROM album_photos WHERE photo_id = ? AND album_id IN ({placeholders})", 
                            [photo_id] + album_ids
                        )
                        albums_to_delete_count = cursor.fetchone()[0]
                        
                        # If photo is only in albums that we're deleting, mark for deletion
                        if album_count == albums_to_delete_count:
                            photos_to_delete.append(photo_id)
                    
                    # Delete photos that are exclusive to these albums
                    photos_deleted = 0
                    if photos_to_delete:
                        photo_placeholders = ','.join(['?'] * len(photos_to_delete))
                        conn.execute(f"DELETE FROM photos WHERE id IN ({photo_placeholders})", photos_to_delete)
                        photos_deleted = len(photos_to_delete)
                    
                    # Delete album-photo associations for these albums
                    conn.execute(f"DELETE FROM album_photos WHERE album_id IN ({placeholders})", album_ids)
                    
                    # Delete the album records
                    conn.execute(f"DELETE FROM albums WHERE id IN ({placeholders})", album_ids)
                    
                    conn.commit()
                
                result = {
                    "success": True,
                    "deleted_albums": len(album_ids),
                    "album_names": list(album_names.values()),
                    "photos_in_albums": len(all_photo_ids),
                    "photos_deleted": photos_deleted,
                    "album_ids": album_ids
                }
                
                self.logger.info("Multiple albums deleted with smart photo cleanup: deleted_albums=%s", len(album_ids),
                               album_names=list(album_names.values()),
                               photos_in_albums=len(all_photo_ids),
                               photos_deleted=photos_deleted)
                
                return result
                
            except Exception as e:
                retry_count += 1
                self.logger.error(f"Failed to delete multiple albums (attempt {retry_count})", 
                                album_ids=album_ids, error=str(e))
                
                # If database is locked, wait and retry
                if "database is locked" in str(e).lower() and retry_count < max_retries:
                    import time
                    time.sleep(0.5 * retry_count)
                    continue
                else:
                    break
        
        return {"success": False, "error": f"Failed to delete albums after {max_retries} attempts"}
    
    def remove_album_photos(self, album_id: int) -> bool:
        """Remove all photos from an album without deleting the photos."""
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                # Use context manager for better connection handling
                with self.get_connection() as conn:
                    conn.execute("DELETE FROM album_photos WHERE album_id = ?", [album_id])
                    conn.commit()
                
                self.logger.info(f"Removed all photos from album: ID {album_id}")
                return True
                
            except Exception as e:
                retry_count += 1
                self.logger.error("Failed to remove album photos (attempt %s): album_id=%s, error=%s", 
                                retry_count, album_id, str(e))
                
                # If database is locked, wait and retry
                if "database is locked" in str(e).lower() and retry_count < max_retries:
                    import time
                    time.sleep(0.5 * retry_count)  # Longer wait time
                    continue
                else:
                    break
        
        return False
    
    def fetch_one(self, query: str, params: tuple = ()) -> Optional[tuple]:
        """Execute a query and return a single row."""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute(query, params)
                return cursor.fetchone()
        except Exception as e:
            self.logger.error(f"Failed to fetch one: query='{query}', error: {str(e)}")
            return None
    
    def fetch_all(self, query: str, params: tuple = ()) -> List[tuple]:
        """Execute a query and return all rows."""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute(query, params)
                return cursor.fetchall()
        except Exception as e:
            self.logger.error(f"Failed to fetch all: query='{query}', error: {str(e)}")
            return []
    


    def find_existing_hashes(self, hashes: List[str], batch_size: int = 1000) -> set:
        """
        æ‰¹é‡æŸ¥è¯¢å·²å­˜åœ¨çš„æ–‡ä»¶å“ˆå¸Œå€¼ã€‚
        
        Args:
            hashes: è¦æŸ¥è¯¢çš„å“ˆå¸Œå€¼åˆ—è¡¨
            batch_size: æ¯æ‰¹æŸ¥è¯¢çš„å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡º
            
        Returns:
            å·²å­˜åœ¨çš„å“ˆå¸Œå€¼é›†åˆ
        """
        try:
            existing_hashes = set()
            
            # åˆ†æ‰¹æŸ¥è¯¢ï¼Œé¿å…å†…å­˜æº¢å‡º
            for i in range(0, len(hashes), batch_size):
                batch_hashes = hashes[i:i + batch_size]
                
                # æž„å»ºæŸ¥è¯¢å‚æ•°
                placeholders = ','.join(['?' for _ in batch_hashes])
                query = f"SELECT file_hash FROM photos WHERE file_hash IN ({placeholders})"
                
                with self.get_connection() as conn:
                    cursor = conn.cursor()
                    cursor.execute(query, batch_hashes)
                    results = cursor.fetchall()
                    
                    # å°†ç»“æžœæ·»åŠ åˆ°é›†åˆä¸­
                    for row in results:
                        existing_hashes.add(row[0])
            
            self.logger.info("Found existing hashes: total_checked=%s, existing_count=%s", len(hashes), len(existing_hashes))
            
            return existing_hashes
            
        except Exception as e:
            self.logger.error(f"Failed to find existing hashes: {str(e)}")
            return set()

    def batch_add_photos_to_album(self, photo_ids: List[int], album_id: int) -> Dict[str, Any]:
        """
        æ‰¹é‡å°†ç…§ç‰‡æ·»åŠ åˆ°ç›¸å†Œã€‚
        
        Args:
            photo_ids: è¦æ·»åŠ çš„ç…§ç‰‡IDåˆ—è¡¨
            album_id: ç›®æ ‡ç›¸å†ŒID
            
        Returns:
            æ“ä½œç»“æžœç»Ÿè®¡
        """
        try:
            if not photo_ids:
                return {"success": True, "added": 0, "skipped": 0, "errors": 0}
            
            added_count = 0
            skipped_count = 0
            error_count = 0
            
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # å¼€å§‹äº‹åŠ¡
                cursor.execute("BEGIN TRANSACTION")
                
                try:
                    # æ£€æŸ¥ç›¸å†Œæ˜¯å¦å­˜åœ¨
                    cursor.execute("SELECT id FROM albums WHERE id = ?", (album_id,))
                    if not cursor.fetchone():
                        raise ValueError(f"Album with ID {album_id} does not exist")
                    
                    # æ£€æŸ¥å“ªäº›ç…§ç‰‡å·²ç»åœ¨ç›¸å†Œä¸­
                    placeholders = ','.join(['?' for _ in photo_ids])
                    cursor.execute(f"""
                        SELECT photo_id FROM album_photos 
                        WHERE album_id = ? AND photo_id IN ({placeholders})
                    """, [album_id] + photo_ids)
                    
                    existing_photo_ids = {row[0] for row in cursor.fetchall()}
                    
                    # æ‰¹é‡æ’å…¥æ–°ç…§ç‰‡
                    current_time = datetime.now().isoformat()
                    for photo_id in photo_ids:
                        if photo_id in existing_photo_ids:
                            skipped_count += 1
                            continue
                        
                        try:
                            cursor.execute("""
                                INSERT INTO album_photos (album_id, photo_id, added_date)
                                VALUES (?, ?, ?)
                            """, (album_id, photo_id, current_time))
                            added_count += 1
                        except Exception as e:
                            self.logger.error("Failed to add photo to album: photo_id=%s, album_id=%s, error=%s", photo_id, album_id, str(e))
                            error_count += 1
                    
                    # æ›´æ–°ç›¸å†Œç…§ç‰‡æ•°é‡
                    cursor.execute("""
                        UPDATE albums 
                        SET photo_count = (
                            SELECT COUNT(*) FROM album_photos WHERE album_id = ?
                        )
                        WHERE id = ?
                    """, (album_id, album_id))
                    
                    # æäº¤äº‹åŠ¡
                    cursor.execute("COMMIT")
                    
                except Exception as e:
                    # å›žæ»šäº‹åŠ¡
                    cursor.execute("ROLLBACK")
                    raise e
            
            result = {
                "success": True,
                "added": added_count,
                "skipped": skipped_count,
                "errors": error_count,
                "total": len(photo_ids)
            }
            
            self.logger.info("Batch add photos to album completed: album_id=%s, added=%s, skipped=%s, errors=%s, total=%s", 
                           album_id, result["added"], result["skipped"], result["errors"], result["total"])
            
            return result
            
        except Exception as e:
            self.logger.error("Failed to batch add photos to album: album_id=%s, error=%s", album_id, str(e))
            return {
                "success": False,
                "added": 0,
                "skipped": 0,
                "errors": len(photo_ids),
                "total": len(photo_ids),
                "error": str(e)
            }

    def batch_insert_photos(self, photos_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰¹é‡æ’å…¥ç…§ç‰‡åˆ°æ•°æ®åº“ã€‚
        
        Args:
            photos_data: ç…§ç‰‡æ•°æ®åˆ—è¡¨
            
        Returns:
            æ“ä½œç»“æžœç»Ÿè®¡
        """
        try:
            if not photos_data:
                return {"success": True, "inserted": 0, "errors": 0}
            
            inserted_count = 0
            error_count = 0
            inserted_ids = []
            
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # å¼€å§‹äº‹åŠ¡
                cursor.execute("BEGIN TRANSACTION")
                
                try:
                    for photo_data in photos_data:
                        try:
                            # å‡†å¤‡ç…§ç‰‡æ•°æ®
                            photo_record = {
                                "filename": photo_data["filename"],
                                "filepath": photo_data["filepath"],
                                "file_size": photo_data.get("file_size", 0),
                                "file_hash": photo_data.get("file_hash", ""),
                                "width": photo_data.get("width", 0),
                                "height": photo_data.get("height", 0),
                                "format": photo_data.get("format", ""),
                                "date_taken": photo_data.get("date_taken", ""),
                                "date_added": photo_data.get("date_added", datetime.now().isoformat()),
                                "date_modified": photo_data.get("date_modified", ""),
                                "exif_data": safe_json_dumps(photo_data.get("exif_data", {})),
                                "ai_metadata": safe_json_dumps(photo_data.get("ai_metadata", {})),
                                "is_ai_generated": photo_data.get("is_ai_generated", False),
                                "tags": safe_json_dumps(photo_data.get("tags", [])),
                                "simple_tags": safe_json_dumps(photo_data.get("simple_tags", [])),
                                "normal_tags": safe_json_dumps(photo_data.get("normal_tags", [])),
                                "detailed_tags": safe_json_dumps(photo_data.get("detailed_tags", [])),
                                "tag_translations": safe_json_dumps(photo_data.get("tag_translations", {})),
                                "rating": photo_data.get("rating", 0),
                                "is_favorite": photo_data.get("is_favorite", False),
                                "thumbnail_path": photo_data.get("thumbnail_path", ""),
                                "notes": photo_data.get("notes", "")
                            }
                            
                            # æ’å…¥ç…§ç‰‡
                            cursor.execute("""
                                INSERT INTO photos (
                                    filename, filepath, file_size, file_hash, width, height,
                                    format, date_taken, date_added, date_modified, exif_data,
                                    ai_metadata, is_ai_generated, tags, simple_tags, normal_tags,
                                    detailed_tags, tag_translations, rating, is_favorite,
                                    thumbnail_path, notes
                                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            """, (
                                photo_record["filename"], photo_record["filepath"],
                                photo_record["file_size"], photo_record["file_hash"],
                                photo_record["width"], photo_record["height"],
                                photo_record["format"], photo_record["date_taken"],
                                photo_record["date_added"], photo_record["date_modified"],
                                photo_record["exif_data"], photo_record["ai_metadata"],
                                photo_record["is_ai_generated"], photo_record["tags"],
                                photo_record["simple_tags"], photo_record["normal_tags"],
                                photo_record["detailed_tags"], photo_record["tag_translations"],
                                photo_record["rating"], photo_record["is_favorite"],
                                photo_record["thumbnail_path"], photo_record["notes"]
                            ))
                            
                            photo_id = cursor.lastrowid
                            inserted_ids.append(photo_id)
                            inserted_count += 1
                            
                        except Exception as e:
                            self.logger.error("Failed to insert photo: filepath=%s", photo_data.get("filepath"), error=str(e))
                            error_count += 1
                    
                    # æäº¤äº‹åŠ¡
                    cursor.execute("COMMIT")
                    
                except Exception as e:
                    # å›žæ»šäº‹åŠ¡
                    cursor.execute("ROLLBACK")
                    raise e
            
            result = {
                "success": True,
                "inserted": inserted_count,
                "errors": error_count,
                "total": len(photos_data),
                "inserted_ids": inserted_ids
            }
            
            self.logger.info("Batch insert photos completed", **result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"Failed to batch insert photos: {str(e)}")
            return {
                "success": False,
                "inserted": 0,
                "errors": len(photos_data),
                "total": len(photos_data),
                "error": str(e)
            }

    def get_all_tags(self) -> List[Dict[str, Any]]:
        """èŽ·å–æ‰€æœ‰æ ‡ç­¾"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT DISTINCT 
                        json_extract(tags.value, '$') as tag_name,
                        COUNT(*) as usage_count
                    FROM photos, json_each(photos.tags) as tags
                    WHERE photos.tags IS NOT NULL AND photos.tags != '[]'
                    GROUP BY tag_name
                    ORDER BY usage_count DESC, tag_name
                """)
                
                tags = []
                for row in cursor.fetchall():
                    tags.append({
                        "name": row[0],
                        "usage_count": row[1]
                    })
                
                return tags
                
        except Exception as e:
            self.logger.error(f"Failed to get all tags: {str(e)}")
            return []

    def save_photo_tags(self, photo_id: int, tags_data: Dict[str, Any]) -> bool:
        """ä¿å­˜ç…§ç‰‡æ ‡ç­¾"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # å‡†å¤‡æ ‡ç­¾æ•°æ® - æ”¯æŒæ–°çš„åˆ†ç¦»å¼æ ‡ç­¾ç»“æž„
                updates = {}
                
                # å¤„ç†åˆ†ç¦»å¼æ ‡ç­¾å­—æ®µ
                if "simple_tags_en" in tags_data:
                    updates["simple_tags_en"] = tags_data.get("simple_tags_en", "")
                if "simple_tags_cn" in tags_data:
                    updates["simple_tags_cn"] = tags_data.get("simple_tags_cn", "")
                if "general_tags_en" in tags_data:
                    updates["general_tags_en"] = tags_data.get("general_tags_en", "")
                if "general_tags_cn" in tags_data:
                    updates["general_tags_cn"] = tags_data.get("general_tags_cn", "")
                if "detailed_tags_en" in tags_data:
                    updates["detailed_tags_en"] = tags_data.get("detailed_tags_en", "")
                if "detailed_tags_cn" in tags_data:
                    updates["detailed_tags_cn"] = tags_data.get("detailed_tags_cn", "")
                if "notes" in tags_data:
                    updates["notes"] = tags_data.get("notes", "")
                
                # å¤„ç†ä¼ ç»Ÿçš„JSONæ ¼å¼æ ‡ç­¾ï¼ˆå‘åŽå…¼å®¹ï¼‰
                if "simple_tags" in tags_data:
                    updates["simple_tags"] = safe_json_dumps(tags_data.get("simple_tags", []))
                if "normal_tags" in tags_data:
                    updates["normal_tags"] = safe_json_dumps(tags_data.get("normal_tags", []))
                if "detailed_tags" in tags_data:
                    updates["detailed_tags"] = safe_json_dumps(tags_data.get("detailed_tags", []))
                if "tag_translations" in tags_data:
                    updates["tag_translations"] = safe_json_dumps(tags_data.get("tag_translations", {}))
                
                if not updates:
                    self.logger.warning(f"No valid tag data provided for photo {photo_id}")
                    return False
                
                # æž„å»ºåŠ¨æ€æ›´æ–°æŸ¥è¯¢
                set_clauses = [f"{field} = ?" for field in updates.keys()]
                values = list(updates.values()) + [photo_id]
                
                query = f"""
                    UPDATE photos 
                    SET {', '.join(set_clauses)}
                    WHERE id = ?
                """
                
                cursor.execute(query, values)
                conn.commit()
                
                if cursor.rowcount > 0:
                    self.logger.info(f"Successfully saved tags for photo {photo_id}")
                    return True
                else:
                    self.logger.warning(f"No photo found with id {photo_id}")
                    return False
                
        except Exception as e:
            self.logger.error(f"Failed to save photo tags {photo_id}: {str(e)}")
            return False
    
    def update_photo_field(self, photo_id: int, field_name: str, field_value: str) -> bool:
        """æ›´æ–°ç…§ç‰‡çš„å•ä¸ªå­—æ®µ"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # éªŒè¯å­—æ®µåæ˜¯å¦å®‰å…¨ï¼ˆé˜²æ­¢SQLæ³¨å…¥ï¼‰
                allowed_fields = [
                    'simple_tags_en', 'simple_tags_cn',
                    'general_tags_en', 'general_tags_cn', 
                    'detailed_tags_en', 'detailed_tags_cn',
                    'notes', 'positive_prompt', 'negative_prompt'
                ]
                
                if field_name not in allowed_fields:
                    self.logger.error(f"Invalid field name: {field_name}")
                    return False
                
                # ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢æ›´æ–°å­—æ®µ
                query = f"UPDATE photos SET {field_name} = ? WHERE id = ?"
                cursor.execute(query, (field_value, photo_id))
                
                conn.commit()
                
                if cursor.rowcount > 0:
                    self.logger.info(f"Updated photo {photo_id} field {field_name}")
                    return True
                else:
                    self.logger.warning(f"No photo found with id {photo_id}")
                    return False
                
        except Exception as e:
            self.logger.error(f"Failed to update photo field {field_name} for photo {photo_id}: {str(e)}")
            return False
    
    def get_photo_albums(self, photo_id: int) -> List[Dict[str, Any]]:
        """èŽ·å–ç…§ç‰‡æ‰€å±žçš„ç›¸å†Œåˆ—è¡¨"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT a.id, a.name, a.description, a.created_date
                    FROM albums a
                    JOIN album_photos ap ON a.id = ap.album_id
                    WHERE ap.photo_id = ?
                    ORDER BY a.name
                """, (photo_id,))
                
                albums = []
                for row in cursor.fetchall():
                    albums.append({
                        "id": row[0],
                        "name": row[1],
                        "description": row[2],
                        "created_date": row[3]
                    })
                
                return albums
                
        except Exception as e:
            self.logger.error(f"Failed to get photo albums for photo {photo_id}: {str(e)}")
            return []
    
    def get_photo_by_id(self, photo_id: int) -> Optional[Dict[str, Any]]:
        """æ ¹æ®IDèŽ·å–ç…§ç‰‡ä¿¡æ¯"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT id, filename, filepath, file_size, file_hash, width, height, 
                           format, date_taken, date_added, is_ai_generated, ai_metadata,
                           simple_tags, normal_tags, detailed_tags, tag_translations,
                           simple_tags_en, simple_tags_cn, general_tags_en, general_tags_cn,
                           detailed_tags_en, detailed_tags_cn, notes,
                           positive_prompt, negative_prompt, rating, is_favorite
                    FROM photos 
                    WHERE id = ?
                """, (photo_id,))
                
                row = cursor.fetchone()
                if row:
                    return {
                        "id": row[0],
                        "filename": row[1],
                        "filepath": row[2],
                        "file_size": row[3],
                        "file_hash": row[4],
                        "width": row[5],
                        "height": row[6],
                        "format": row[7],
                        "date_taken": row[8],
                        "date_added": row[9],
                        "is_ai_generated": row[10],
                        "ai_metadata": row[11],
                        "simple_tags": row[12],
                        "normal_tags": row[13],
                        "detailed_tags": row[14],
                        "tag_translations": row[15],
                        "simple_tags_en": row[16],
                        "simple_tags_cn": row[17],
                        "general_tags_en": row[18],
                        "general_tags_cn": row[19],
                        "detailed_tags_en": row[20],
                        "detailed_tags_cn": row[21],
                        "notes": row[22],
                        "positive_prompt": row[23],
                        "negative_prompt": row[24],
                        "rating": row[25],
                        "is_favorite": row[26]
                    }
                return None
                
        except Exception as e:
            self.logger.error(f"Failed to get photo by ID {photo_id}: {str(e)}")
            return None
    
    def get_recent_albums(self, limit: int = 5) -> List[Dict[str, Any]]:
        """èŽ·å–æœ€è¿‘ä½¿ç”¨çš„ç›¸å†Œåˆ—è¡¨"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                     SELECT a.id, a.name, a.description, a.created_date, 
                            COUNT(ap.photo_id) as photo_count,
                            MAX(ap.added_date) as last_photo_added
                     FROM albums a
                     LEFT JOIN album_photos ap ON a.id = ap.album_id
                     GROUP BY a.id, a.name, a.description, a.created_date
                     ORDER BY last_photo_added DESC, a.created_date DESC
                     LIMIT ?
                 """, (limit,))
                
                albums = []
                for row in cursor.fetchall():
                    albums.append({
                        "id": row[0],
                        "name": row[1],
                        "description": row[2],
                        "created_date": row[3],
                        "photo_count": row[4],
                        "last_photo_added": row[5]
                    })
                
                return albums
                
        except Exception as e:
            self.logger.error(f"Failed to get recent albums: {str(e)}")
            return []